{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bc713cda",
      "metadata": {
        "id": "bc713cda"
      },
      "source": [
        "# Machine Learning - Practical 4 - Deep Learning VS Trees\n",
        "\n",
        "\n",
        "Names: {YOUR NAMES}  \n",
        "Summer Term 2023   \n",
        "Due Date: Tuesday, June 13, 2pm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0e394c4e",
      "metadata": {
        "id": "0e394c4e"
      },
      "source": [
        "In this practical we are going to use a tabular dataset. We will test two different approaches - forests and neural networks and compare performance. We are also going to learn how to make trees interpretable."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "72933ee7",
      "metadata": {
        "id": "72933ee7"
      },
      "source": [
        "To prepare this tutorial we used [this paper](https://arxiv.org/pdf/2207.08815.pdf) with its [repository](https://github.com/LeoGrin/tabular-benchmark).\n",
        "\n",
        "For explained variance in trees, you can read more [here](https://scikit-learn.org/0.15/auto_examples/ensemble/plot_gradient_boosting_regression.html#example-ensemble-plot-gradient-boosting-regression-py).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "218de310",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "218de310",
        "outputId": "93864191-1b7e-479f-bfd3-0759b4847266",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x14c77a02e30>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "torch.manual_seed(42) # Set manual seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3bb2c837",
      "metadata": {
        "id": "3bb2c837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device cuda:0\n"
          ]
        }
      ],
      "source": [
        "# DO NOT CHANGE\n",
        "use_cuda = True\n",
        "use_cuda = False if not use_cuda else torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
        "torch.cuda.get_device_name(device) if use_cuda else 'cpu'\n",
        "print('Using device', device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8e24771e",
      "metadata": {
        "id": "8e24771e"
      },
      "source": [
        "## Load, clean and split the tabular dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "61d9f9e1",
      "metadata": {
        "id": "61d9f9e1"
      },
      "source": [
        "We use the preprocessing pipeline from [Grinsztajn, 2022](https://arxiv.org/pdf/2207.08815.pdf).\n",
        "\n",
        "**No missing data**    \n",
        "\n",
        "Remove all rows containing at least one missing entry.    \n",
        "\n",
        "*In practice people often do not remove rows with missing values but try to fill missing values in a column with the mean or median values for numerical data and mode or median values for categorical data. Sometimes even simple prediction models are used to fill in the gaps but we will remove rows or columns with missing values for the sake of simplicity*\n",
        "\n",
        "**Balanced classes**   \n",
        "\n",
        "For classification, the target is binarised if there are multiple classes, by taking the two most numerous classes, and we keep half of samples in each class.\n",
        "\n",
        "**Low cardinality categorical features**   \n",
        "\n",
        "Remove categorical features with more than 20 items. \n",
        "\n",
        "**High cardinality numerical features**   \n",
        "\n",
        "Remove numerical features with less than 10 unique values. Convert numerical features with 2 unique values to categorical."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "Gyi3ep5EtiIf",
      "metadata": {
        "id": "Gyi3ep5EtiIf"
      },
      "source": [
        "**Data description:**  \n",
        "Data reported to the police about the circumstances of personal injury road accidents in Great Britain from 1979. This version includes data up to 2015. We will try to predict the sex of the driver based on the data provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bbc76543",
      "metadata": {
        "id": "bbc76543"
      },
      "outputs": [],
      "source": [
        "## In case you have any issues with loading the pickle file\n",
        "## check that your pandas version is 1.4.1\n",
        "## or just simply run:\n",
        "## pip install pandas==1.4.1\n",
        "\n",
        "with open('adopted_road_safety.pkl', 'rb') as f:\n",
        "    dataset = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "288e7151",
      "metadata": {
        "id": "288e7151"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accident_Index</th>\n",
              "      <th>Vehicle_Reference_df_res</th>\n",
              "      <th>Vehicle_Type</th>\n",
              "      <th>Towing_and_Articulation</th>\n",
              "      <th>Vehicle_Manoeuvre</th>\n",
              "      <th>Vehicle_Location-Restricted_Lane</th>\n",
              "      <th>Junction_Location</th>\n",
              "      <th>Skidding_and_Overturning</th>\n",
              "      <th>Hit_Object_in_Carriageway</th>\n",
              "      <th>Vehicle_Leaving_Carriageway</th>\n",
              "      <th>...</th>\n",
              "      <th>Age_Band_of_Casualty</th>\n",
              "      <th>Casualty_Severity</th>\n",
              "      <th>Pedestrian_Location</th>\n",
              "      <th>Pedestrian_Movement</th>\n",
              "      <th>Car_Passenger</th>\n",
              "      <th>Bus_or_Coach_Passenger</th>\n",
              "      <th>Pedestrian_Road_Maintenance_Worker</th>\n",
              "      <th>Casualty_Type</th>\n",
              "      <th>Casualty_Home_Area_Type</th>\n",
              "      <th>Casualty_IMD_Decile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201501BS70001</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201501BS70002</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201501BS70004</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>201501BS70005</td>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>201501BS70008</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363238</th>\n",
              "      <td>2015984141415</td>\n",
              "      <td>13</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363239</th>\n",
              "      <td>2015984141415</td>\n",
              "      <td>13</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363240</th>\n",
              "      <td>2015984141415</td>\n",
              "      <td>13</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363241</th>\n",
              "      <td>2015984141415</td>\n",
              "      <td>13</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363242</th>\n",
              "      <td>2015984141415</td>\n",
              "      <td>13</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>363243 rows Ã— 67 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Accident_Index  Vehicle_Reference_df_res  Vehicle_Type   \n",
              "0       201501BS70001                         1          19.0  \\\n",
              "1       201501BS70002                         1           9.0   \n",
              "2       201501BS70004                         1           9.0   \n",
              "3       201501BS70005                         1           9.0   \n",
              "4       201501BS70008                         1           1.0   \n",
              "...               ...                       ...           ...   \n",
              "363238  2015984141415                        13           9.0   \n",
              "363239  2015984141415                        13           9.0   \n",
              "363240  2015984141415                        13           9.0   \n",
              "363241  2015984141415                        13           9.0   \n",
              "363242  2015984141415                        13           9.0   \n",
              "\n",
              "        Towing_and_Articulation  Vehicle_Manoeuvre   \n",
              "0                           0.0                9.0  \\\n",
              "1                           0.0                9.0   \n",
              "2                           0.0                9.0   \n",
              "3                           0.0                9.0   \n",
              "4                           0.0               18.0   \n",
              "...                         ...                ...   \n",
              "363238                      0.0               18.0   \n",
              "363239                      0.0               18.0   \n",
              "363240                      0.0               18.0   \n",
              "363241                      0.0               18.0   \n",
              "363242                      0.0               18.0   \n",
              "\n",
              "        Vehicle_Location-Restricted_Lane  Junction_Location   \n",
              "0                                    0.0                8.0  \\\n",
              "1                                    0.0                8.0   \n",
              "2                                    0.0                2.0   \n",
              "3                                    0.0                2.0   \n",
              "4                                    0.0                8.0   \n",
              "...                                  ...                ...   \n",
              "363238                               0.0                0.0   \n",
              "363239                               0.0                0.0   \n",
              "363240                               0.0                0.0   \n",
              "363241                               0.0                0.0   \n",
              "363242                               0.0                0.0   \n",
              "\n",
              "        Skidding_and_Overturning  Hit_Object_in_Carriageway   \n",
              "0                            0.0                        0.0  \\\n",
              "1                            0.0                        0.0   \n",
              "2                            0.0                        0.0   \n",
              "3                            0.0                        0.0   \n",
              "4                            0.0                        0.0   \n",
              "...                          ...                        ...   \n",
              "363238                       0.0                        0.0   \n",
              "363239                       0.0                        0.0   \n",
              "363240                       0.0                        0.0   \n",
              "363241                       0.0                        0.0   \n",
              "363242                       0.0                        0.0   \n",
              "\n",
              "        Vehicle_Leaving_Carriageway  ...  Age_Band_of_Casualty   \n",
              "0                               0.0  ...                   7.0  \\\n",
              "1                               0.0  ...                   5.0   \n",
              "2                               0.0  ...                   6.0   \n",
              "3                               0.0  ...                   2.0   \n",
              "4                               0.0  ...                   8.0   \n",
              "...                             ...  ...                   ...   \n",
              "363238                          5.0  ...                   1.0   \n",
              "363239                          5.0  ...                   5.0   \n",
              "363240                          5.0  ...                   4.0   \n",
              "363241                          5.0  ...                   6.0   \n",
              "363242                          5.0  ...                   4.0   \n",
              "\n",
              "        Casualty_Severity  Pedestrian_Location  Pedestrian_Movement   \n",
              "0                       3                  5.0                  1.0  \\\n",
              "1                       3                  9.0                  9.0   \n",
              "2                       3                  1.0                  3.0   \n",
              "3                       3                  5.0                  1.0   \n",
              "4                       2                  0.0                  0.0   \n",
              "...                   ...                  ...                  ...   \n",
              "363238                  3                  0.0                  0.0   \n",
              "363239                  3                  0.0                  0.0   \n",
              "363240                  3                  0.0                  0.0   \n",
              "363241                  3                  0.0                  0.0   \n",
              "363242                  3                  0.0                  0.0   \n",
              "\n",
              "       Car_Passenger  Bus_or_Coach_Passenger   \n",
              "0                0.0                     0.0  \\\n",
              "1                0.0                     0.0   \n",
              "2                0.0                     0.0   \n",
              "3                0.0                     0.0   \n",
              "4                0.0                     0.0   \n",
              "...              ...                     ...   \n",
              "363238           2.0                     0.0   \n",
              "363239           0.0                     0.0   \n",
              "363240           0.0                     0.0   \n",
              "363241           0.0                     0.0   \n",
              "363242           0.0                     0.0   \n",
              "\n",
              "        Pedestrian_Road_Maintenance_Worker  Casualty_Type   \n",
              "0                                      2.0              0  \\\n",
              "1                                      2.0              0   \n",
              "2                                      2.0              0   \n",
              "3                                      2.0              0   \n",
              "4                                      0.0              1   \n",
              "...                                    ...            ...   \n",
              "363238                                 0.0              9   \n",
              "363239                                 0.0              9   \n",
              "363240                                 0.0              9   \n",
              "363241                                 0.0              9   \n",
              "363242                                 0.0              9   \n",
              "\n",
              "        Casualty_Home_Area_Type  Casualty_IMD_Decile  \n",
              "0                           NaN                  NaN  \n",
              "1                           1.0                  3.0  \n",
              "2                           1.0                  6.0  \n",
              "3                           1.0                  2.0  \n",
              "4                           1.0                  3.0  \n",
              "...                         ...                  ...  \n",
              "363238                      1.0                  NaN  \n",
              "363239                      1.0                  2.0  \n",
              "363240                      2.0                  5.0  \n",
              "363241                      3.0                  NaN  \n",
              "363242                      1.0                  4.0  \n",
              "\n",
              "[363243 rows x 67 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fAWW5kChD6MU",
      "metadata": {
        "id": "fAWW5kChD6MU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of genders: 3\n",
            "Genders:           ['1.0' '2.0' '3.0']\n"
          ]
        }
      ],
      "source": [
        "target_column = 'Sex_of_Driver'\n",
        "test_size = 0.2\n",
        "random_state = 42\n",
        "\n",
        "# Take a look at the gender variable\n",
        "print(f'Number of genders: {len(np.unique(dataset[target_column]))}')\n",
        "print(f'Genders:           {np.unique(dataset[target_column])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3d77435f",
      "metadata": {
        "id": "3d77435f"
      },
      "outputs": [],
      "source": [
        "def remove_nans(df):\n",
        "    '''\n",
        "    This function removes rows with NaN values.\n",
        "    '''\n",
        "\n",
        "    # Drop rows with NaN values\n",
        "    cleaned_df = df.dropna()  \n",
        "\n",
        "    return cleaned_df\n",
        "\n",
        "\n",
        "def numerical_to_categorical(df, n=2, ignore=[target_column]):\n",
        "    '''\n",
        "    Change the type of the column to categorical \n",
        "    if it has <= n unique values.\n",
        "    '''\n",
        "    # terate over columns\n",
        "    for column in df.columns:\n",
        "\n",
        "        if column not in ignore:\n",
        "            # Calculate the number of unique values in the column\n",
        "            unique_values = df[column].nunique()  \n",
        "\n",
        "            # Change column type to categorical if condition is met\n",
        "            if unique_values <= n:\n",
        "                df[column] = df[column].astype('category')  \n",
        "        else:\n",
        "            # If the column is in the ignore list, do nothing\n",
        "            pass\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def remove_columns_by_n(df, n=10, condition=np.number, direction='less', ignore=[target_column]):\n",
        "    '''\n",
        "    Remove columns with more or less than n unique values.\n",
        "    Usually it makes sense to apply this function to columns with categorical values.\n",
        "    With the default values, we remove all numerical columns which have less than 10 unique values (except for the target_column).\n",
        "    '''\n",
        "\n",
        "    # Iterate over each column in the DataFrame\n",
        "    for column in df.columns:\n",
        "        \n",
        "        # Calculate number of unique values in current column\n",
        "        n_unique = df[column].nunique()\n",
        "\n",
        "        # Check if column should be ignored or is equal to target_column\n",
        "        if column not in ignore:\n",
        "\n",
        "            # Check direction parameter and compare unique value count with n\n",
        "            if direction == 'less' and n_unique < n:\n",
        "                df.drop(column, axis=1, inplace=True)\n",
        "            \n",
        "            elif direction == 'more' and n_unique > n:\n",
        "                df.drop(column, axis=1, inplace=True)\n",
        "        else:\n",
        "            # If the column is in the ignore list, do nothing\n",
        "            pass\n",
        "        \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9033619f",
      "metadata": {
        "id": "9033619f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column] = df[column].astype('category')\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n",
            "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_12020\\3462726867.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(column, axis=1, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "df = dataset\n",
        "df = remove_nans(df)\n",
        "df = numerical_to_categorical(df, n=2, ignore=[target_column])\n",
        "df = remove_columns_by_n(df, n=10, condition=np.number, direction='less', \n",
        "                         ignore=[target_column])\n",
        "df = remove_columns_by_n(df, n=40, condition='category', direction='more', \n",
        "                         ignore=[target_column])\n",
        "assert not df.isna().any().any(), 'There are still nans in the dataframe'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "22348559",
      "metadata": {
        "id": "22348559"
      },
      "outputs": [],
      "source": [
        "# TODO : make train-test split from the dataframe using the parameters above\n",
        "# expected results variable names - train_X, test_X, train_y, test_y\n",
        "\n",
        "X = df.drop(columns=[target_column])\n",
        "Y = df[target_column]\n",
        "\n",
        "# Perform train-test split\n",
        "rest_X, test_X, rest_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "train_X, val_X, train_y, val_y = train_test_split(rest_X, rest_y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "77f002d6",
      "metadata": {
        "id": "77f002d6"
      },
      "source": [
        "**TODO :**  \n",
        "\n",
        "* Did you split the dataset in a stratified manner or not? Why?\n",
        "* How did the dataset dimensions change after preprocessing?\n",
        "* How many unique values are in the response variable? "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f309f4d6",
      "metadata": {
        "id": "f309f4d6"
      },
      "source": [
        "## Task 1: Create a GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cxbPa0evFrRF",
      "metadata": {
        "id": "cxbPa0evFrRF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6635004671441919\n"
          ]
        }
      ],
      "source": [
        "## TODO : define the GradientBoostingClassifier, \n",
        "## train it on the train set and predict on the test set\n",
        "\n",
        "# Define the GradientBoostingClassifier\n",
        "model = GradientBoostingClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_X, train_y)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_X)\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy = accuracy_score(test_y, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "YZ5j6BMKFrcJ",
      "metadata": {
        "id": "YZ5j6BMKFrcJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6635004671441919\n",
            "Precision: 0.634857528670063\n",
            "Recall: 0.6635004671441919\n"
          ]
        }
      ],
      "source": [
        "## TODO : print  accuracy, precision, recall\n",
        "## Hint : use functions from sklearn metrics\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_y, predictions)\n",
        "\n",
        "# Calculate precision (change average parameter to 'micro', 'macro', or 'weighted')\n",
        "precision = precision_score(test_y, predictions, average='weighted')\n",
        "\n",
        "# Calculate recall (change average parameter to 'micro', 'macro', or 'weighted')\n",
        "recall = recall_score(test_y, predictions, average='weighted')\n",
        "\n",
        "# Print the scores\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "598f0ffa",
      "metadata": {
        "id": "598f0ffa"
      },
      "outputs": [],
      "source": [
        "## TODO : Write a function which iterates over trees_amount, \n",
        "## train a classifier with a specified amount of trees and print accuracy, precision, and recall.\n",
        "## Note: the calculations may take several minutes (depending on the computer efficiency).\n",
        "\n",
        "def trees_amount_exploration(train_X, train_y, test_X, test_y, trees_amount=[1, 20, 50, 100]):\n",
        "    for num_trees in trees_amount:\n",
        "        # Define the GradientBoostingClassifier with the specified number of trees\n",
        "        model = GradientBoostingClassifier(n_estimators=num_trees)\n",
        "\n",
        "        # Train the model on the training set\n",
        "        model.fit(train_X, train_y)\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        predictions = model.predict(test_X)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(test_y, predictions)\n",
        "\n",
        "        # Calculate precision\n",
        "        precision = precision_score(test_y, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "        # Calculate recall\n",
        "        recall = recall_score(test_y, predictions, average='weighted')\n",
        "\n",
        "        # Print the scores\n",
        "        print(f'Number of Trees: {num_trees}')\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print(f'Precision: {precision}')\n",
        "        print(f'Recall: {recall}\\n\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "qcnxg4InEkRl",
      "metadata": {
        "id": "qcnxg4InEkRl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Trees: 1\n",
            "Accuracy: 0.6514585279767466\n",
            "Precision: 0.4245319473442403\n",
            "Recall: 0.6514585279767466\n",
            "\n",
            "\n",
            "Number of Trees: 20\n",
            "Accuracy: 0.6518218623481782\n",
            "Precision: 0.7716280102146362\n",
            "Recall: 0.6518218623481782\n",
            "\n",
            "\n",
            "Number of Trees: 50\n",
            "Accuracy: 0.6587771203155819\n",
            "Precision: 0.6323910929244663\n",
            "Recall: 0.6587771203155819\n",
            "\n",
            "\n",
            "Number of Trees: 100\n",
            "Accuracy: 0.6635523720543963\n",
            "Precision: 0.6349809362168943\n",
            "Recall: 0.6635523720543963\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trees_amount_exploration(train_X, train_y, test_X, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "518fc198",
      "metadata": {},
      "outputs": [],
      "source": [
        "## TODO : Write a function which iterates over the learning rate, \n",
        "## train a classifier with a specified amount of trees and print accuracy, precision, and recall.\n",
        "## Note: the calculations may take several minutes (depending on the computer efficiency).\n",
        "\n",
        "def learning_rate_exploration(train_X, train_y, test_X, test_y, learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5], trees_amount=100):\n",
        "    \n",
        "    for lr in learning_rates:\n",
        "\n",
        "        # Define the GradientBoostingClassifier with the specified number of trees\n",
        "        model = GradientBoostingClassifier(learning_rate = lr, n_estimators = trees_amount)\n",
        "\n",
        "        # Train the model on the training set\n",
        "        model.fit(train_X, train_y)\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        predictions = model.predict(test_X)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(test_y, predictions)\n",
        "\n",
        "        # Calculate precision\n",
        "        precision = precision_score(test_y, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "        # Calculate recall\n",
        "        recall = recall_score(test_y, predictions, average='weighted')\n",
        "\n",
        "        # Print the scores\n",
        "        print(f'Learning Rate: {lr}')\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print(f'Precision: {precision}')\n",
        "        print(f'Recall: {recall}\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "afb2ae07",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning Rate: 0.1\n",
            "Accuracy: 0.6635523720543963\n",
            "Precision: 0.6349809362168943\n",
            "Recall: 0.6635523720543963\n",
            "\n",
            "\n",
            "Learning Rate: 0.2\n",
            "Accuracy: 0.6660438077442126\n",
            "Precision: 0.6380476234292847\n",
            "Recall: 0.6660438077442126\n",
            "\n",
            "\n",
            "Learning Rate: 0.3\n",
            "Accuracy: 0.6670819059483027\n",
            "Precision: 0.6393752322681612\n",
            "Recall: 0.6670819059483027\n",
            "\n",
            "\n",
            "Learning Rate: 0.4\n",
            "Accuracy: 0.6668742863074847\n",
            "Precision: 0.6392981260194021\n",
            "Recall: 0.6668742863074847\n",
            "\n",
            "\n",
            "Learning Rate: 0.5\n",
            "Accuracy: 0.6667185715768712\n",
            "Precision: 0.639005721856785\n",
            "Recall: 0.6667185715768712\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "learning_rate_exploration(train_X, train_y, test_X, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "T-akqJfbEkVF",
      "metadata": {
        "id": "T-akqJfbEkVF"
      },
      "outputs": [],
      "source": [
        "## TODO : Write a function which iterates over different depths, \n",
        "## train a classifier with a specified depth and print accuracy, precision, and recall\n",
        "## Set trees_amount= 50 to make the calculations faster\n",
        "## Note: the calculations may take several minutes (depending on the computer efficiency).\n",
        "\n",
        "def max_depth_exploration(train_X, train_y, test_X, test_y, depths=[1,2,3,4,5] , trees_amount = 50):\n",
        "        \n",
        "    for depth in depths:\n",
        "        # Define the GradientBoostingClassifier with the specified depth and number of trees\n",
        "        model = GradientBoostingClassifier(max_depth = depth, n_estimators = trees_amount)\n",
        "\n",
        "        # Train the model on the training set\n",
        "        model.fit(train_X, train_y)\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        predictions = model.predict(test_X)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(test_y, predictions)\n",
        "\n",
        "        # Calculate precision\n",
        "        precision = precision_score(test_y, predictions, average = 'weighted', zero_division = 0)\n",
        "\n",
        "        # Calculate recall\n",
        "        recall = recall_score(test_y, predictions, average='weighted')\n",
        "\n",
        "        # Print the scores\n",
        "        print(f\"Depth: {depth}\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3oFAnFOnEkdX",
      "metadata": {
        "id": "3oFAnFOnEkdX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Depth: 1\n",
            "Accuracy: 0.6515623377971557\n",
            "Precision: 0.42453348003569474\n",
            "Recall: 0.6515623377971557\n",
            "\n",
            "\n",
            "Depth: 2\n",
            "Accuracy: 0.6537423440257448\n",
            "Precision: 0.6454733568436177\n",
            "Recall: 0.6537423440257448\n",
            "\n",
            "\n",
            "Depth: 3\n",
            "Accuracy: 0.6587771203155819\n",
            "Precision: 0.6323910929244663\n",
            "Recall: 0.6587771203155819\n",
            "\n",
            "\n",
            "Depth: 4\n",
            "Accuracy: 0.6614761756462161\n",
            "Precision: 0.6333118680413113\n",
            "Recall: 0.6614761756462161\n",
            "\n",
            "\n",
            "Depth: 5\n",
            "Accuracy: 0.6652133291809406\n",
            "Precision: 0.6395109553725793\n",
            "Recall: 0.6652133291809406\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "max_depth_exploration(train_X, train_y, test_X, test_y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "75fc86d1",
      "metadata": {
        "id": "75fc86d1"
      },
      "source": [
        "**TODO :**   \n",
        "\n",
        "* How does the max_depth parameter influence the results? \n",
        "* How does the learning rate influence the results?\n",
        "* How does the number of trees in the ensemble influence the results?\n",
        "* Try to improve the accuracy by combining different max_depth, learning rate and number of trees. How well does your best model perform?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "aa0c330e",
      "metadata": {
        "id": "aa0c330e"
      },
      "outputs": [],
      "source": [
        "## TODO -  sklearn trees have the attribute feature_importances_\n",
        "## make a plot, to show relative importance (maximum is 1) of your classifier and\n",
        "## order features from most relevant feature to the least relevant in the plot\n",
        "\n",
        "def plot_explained_variance(clf, X):\n",
        "    # Get feature importances from the classifier\n",
        "    importances = clf.feature_importances_\n",
        "\n",
        "    # Get feature names from the feature matrix\n",
        "    feature_names = X.columns\n",
        "\n",
        "    # Sort feature importances in descending order\n",
        "    sorted_indices = importances.argsort()[::-1]\n",
        "    sorted_importances = importances[sorted_indices][::-1]\n",
        "    sorted_feature_names = feature_names[sorted_indices][::-1]\n",
        "\n",
        "    # Create a horizontal bar plot to show relative feature importances\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(range(len(sorted_importances)), sorted_importances, align='center')\n",
        "    plt.yticks(range(len(sorted_importances)), sorted_feature_names)\n",
        "    plt.xlabel('Relative Importance')\n",
        "    plt.ylabel('Features')\n",
        "    plt.title('Feature Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6cf90239",
      "metadata": {
        "id": "6cf90239"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## TODO : display the plot\n",
        "plot_explained_variance(model, train_X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2e0872d8",
      "metadata": {
        "id": "2e0872d8"
      },
      "source": [
        "**TODO :** Interpret the plot.\n",
        "\n",
        "**TODO (optional):** Try to remove the least-important features and see what happens. Does to quality improve or degrade? Why? "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "jhE75y_UN7Qx",
      "metadata": {
        "id": "jhE75y_UN7Qx"
      },
      "source": [
        "## Prepare for deep learning\n",
        "### Add all the necessary training functions \n",
        "*You can reuse them from previous practical exercises*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LfDLPO2QODES",
      "metadata": {
        "id": "LfDLPO2QODES"
      },
      "outputs": [],
      "source": [
        "## TODO write a function that calculates the accuracy\n",
        "## Hint - you can use yours from practical 3 \n",
        "\n",
        "def accuracy(correct, total): \n",
        "    \"\"\"\n",
        "    function to calculate the accuracy given the\n",
        "        correct: number of correctly classified samples\n",
        "        total: total number of samples\n",
        "    returns the ratio\n",
        "    \"\"\"\n",
        "    ratio = correct/total\n",
        "\n",
        "    return ratio\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EVe7SFnrODHP",
      "metadata": {
        "id": "EVe7SFnrODHP"
      },
      "outputs": [],
      "source": [
        "## TODO : Define a train and validation functions here\n",
        "## Hint - you can use yours from practical 3 \n",
        "\n",
        "def train(dataloader, optimizer, model, loss_fn, device):\n",
        "    \"\"\"Method to train the model\"\"\"\n",
        "\n",
        "  # TODO: refine the training function from above\n",
        "  # it should contain:\n",
        "  # - saving of losses\n",
        "  # - calculation of accuracy\n",
        "  # - returning the mean loss and accuracy\n",
        "\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Initialize loss and accuracy variables\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterate over batches in dataloader\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        # Move input data and labels to GPU\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Reset gradients of the optimizer to avoid gradient accumulation\n",
        "        # allows optimizer to perform accurate/independent updates for each batch, resulting in better convergence\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: compute the predicted outputs of the model\n",
        "        y_pred = model.forward(x)\n",
        "\n",
        "        # Compute the loss between the predicted outputs and true labels\n",
        "        loss = loss_fn(y_pred.squeeze(), y)\n",
        "\n",
        "        # Backward pass: compute the gradients of the model parameters with respect to the loss\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model parameters using the gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the training loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy of the predicted outputs comparing them to true labels\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "\n",
        "    # Calculate mean training loss over all batches\n",
        "    train_loss /= len(dataloader)\n",
        "\n",
        "    # Calculate training accuracy\n",
        "    train_accuracy = accuracy(correct, total)\n",
        "\n",
        "    # Return mean training loss and accuracy\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def validate(val_dataloader, model, loss_fn, device):\n",
        "    \"\"\" method to compute the metrics on the validation set \"\"\"\n",
        "    # TODO: write a validation function that calculates the loss and accuracy on the validation set\n",
        "    # you can also combine it with the training function\n",
        "    \n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize variables to track loss and accuracy\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Disable gradient computation during validation\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the batches in the validation dataloader\n",
        "        for i, (x_val, y_val) in enumerate(val_dataloader):\n",
        "            # Move the validation data and labels to the specified device\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "\n",
        "            # Forward pass: compute the predicted outputs of the model\n",
        "            y_pred_val = model(x_val)\n",
        "\n",
        "            # Compute loss between the predicted outputs and true labels\n",
        "            loss_val = loss_fn(y_pred_val.squeeze(), y_val)\n",
        "\n",
        "            # Accumulate validation loss\n",
        "            val_loss += loss_val.item()\n",
        "\n",
        "            # Calculate the accuracy of the predicted outputs by comparing them to true labels\n",
        "            _, predicted_val = torch.max(y_pred_val.data, 1)\n",
        "            total += y_val.size(0) # 0 = first dimnesion in tensor\n",
        "            correct += (predicted_val == y_val).sum().item()\n",
        "\n",
        "        # Calculate mean validation loss over all batches\n",
        "        val_loss /= len(val_dataloader)\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        val_accuracy = accuracy(correct, total)\n",
        "\n",
        "    # Return mean validation loss and accuracy\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "pzGM0bPqxw3V",
      "metadata": {
        "id": "pzGM0bPqxw3V"
      },
      "outputs": [],
      "source": [
        "#TODO write a run_training function that \n",
        "# - calls the train and validate functions for each epoch\n",
        "# - saves the train_losses, val_losses, train_accs, val_accs as arrays for each epoch\n",
        "## Hint - you can use yours from practical 3 \n",
        "from tqdm import trange\n",
        "\n",
        "\n",
        "def run_training(model, optimizer, loss_function, device, num_epochs, train_dataloader, test_dataloader):\n",
        "    \"\"\"Method to run the training procedure\"\"\"\n",
        "  # TODO: write a run_training function that \n",
        "  # - calls the train and validate functions for each epoch\n",
        "  # - saves the train_losses, val_losses, train_accs, val_accs as arrays for each epoch\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    # Iterate over number of epochs using tqdm(trange) for progress bar\n",
        "    for epoch in trange(num_epochs, desc='Epoch'):\n",
        "        # Perform training for the current epoch\n",
        "        train_loss, train_accuracy = train(train_dataloader, optimizer, model, loss_function, device)\n",
        "\n",
        "        # Perform validation for the current epoch\n",
        "        val_loss, val_accuracy = validate(test_dataloader, model, loss_function, device)\n",
        "\n",
        "        # Append the values to repective list\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    # Return lists\n",
        "    return train_losses, val_losses, train_accs, val_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ngflrAEJxw5t",
      "metadata": {
        "id": "ngflrAEJxw5t"
      },
      "outputs": [],
      "source": [
        "# TODO write a plot function \n",
        "## Hint - you can use yours from practical 2 or 3 \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9iqaRi2xRADg",
      "metadata": {
        "id": "9iqaRi2xRADg"
      },
      "source": [
        "### Convert a pandas dataframe to a PyTorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e3dcbc2c",
      "metadata": {
        "id": "e3dcbc2c"
      },
      "outputs": [],
      "source": [
        "## TODO : Define the dataset, apply normalization in the getitem method\n",
        "## Hint : you can use/adapt your code from practical 2\n",
        "class TabularDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df_x, df_y, mean=None, std=None, normalise=True):\n",
        "        '''\n",
        "        Initialize the TabularDataset class.\n",
        "        \n",
        "        Args:\n",
        "        - df_x (pd.DataFrame): DataFrame containing the input features.\n",
        "        - df_y (pd.Series): Series containing the target variable.\n",
        "        - mean (np.array): Mean values for normalization (optional).\n",
        "        - std (np.array): Standard deviation values for normalization (optional).\n",
        "        - normalise (bool): Flag indicating whether to normalize the data (optional).\n",
        "        '''\n",
        "        self.x = df_x.to_numpy()\n",
        "        self.y = df_y.to_numpy()\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.normalise = normalise\n",
        "\n",
        "        # Normalize the data if needed\n",
        "        if self.normalise:\n",
        "            self.x = self.normalize_data(self.x, self.mean, self.std)\n",
        "    \n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Return the length of the dataset.\n",
        "        '''\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        Return the input features (X) and target variable (y) by index.\n",
        "        \n",
        "        Args:\n",
        "        - index (int): Index of the data sample.\n",
        "        \n",
        "        Returns:\n",
        "        - X (np.array): Input features for the specified index.\n",
        "        - y (int): Target variable for the specified index.\n",
        "        '''\n",
        "        X = self.x[index]\n",
        "        y = self.y[index]\n",
        "        return X, y\n",
        "    \n",
        "    def normalize_data(self, data, mean, std):\n",
        "        '''\n",
        "        Normalize the data using mean and standard deviation values.\n",
        "        \n",
        "        Args:\n",
        "        - data (np.array): Data to be normalized.\n",
        "        - mean (np.array): Mean values for normalization.\n",
        "        - std (np.array): Standard deviation values for normalization.\n",
        "        \n",
        "        Returns:\n",
        "        - normalized_data (np.array): Normalized data.\n",
        "        '''\n",
        "        normalized_data = (data - mean) / std\n",
        "        return normalized_data\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "3jJXxpF-KIpz",
      "metadata": {
        "id": "3jJXxpF-KIpz"
      },
      "outputs": [],
      "source": [
        "## TODO : calculate mean and std for the train set\n",
        "## Hint : be careful with categorical values. Convert them them to numerical \n",
        "## Hint : the response variable should be of datatype integer\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert categorical columns to numerical representation\n",
        "categorical_cols = train_X.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    train_X[col] = label_encoders[col].fit_transform(train_X[col])\n",
        "    test_X[col] = label_encoders[col].transform(test_X[col])\n",
        "\n",
        "# Convert the response variable to the float datatype\n",
        "train_y = train_y.astype(float)\n",
        "test_y = test_y.astype(float)\n",
        "\n",
        "# Calculate mean and standard deviation for the train set\n",
        "train_mean = train_X.mean()\n",
        "train_std = train_X.std()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "Ef6dNkihxzYd",
      "metadata": {
        "id": "Ef6dNkihxzYd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(61648, 14)\n",
            "(61648,)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Length of values (61648) does not match length of index (14)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(train_y\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Create new datasets with mean, std, and normalization\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m train_dataset \u001b[39m=\u001b[39m TabularDataset(train_X, train_y, mean\u001b[39m=\u001b[39;49mtrain_mean, std\u001b[39m=\u001b[39;49mtrain_std, normalise\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     15\u001b[0m test_dataset \u001b[39m=\u001b[39m TabularDataset(test_X, test_y, mean\u001b[39m=\u001b[39mtrain_mean, std\u001b[39m=\u001b[39mtrain_std, normalise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Create the data loaders with the specified batch size and shuffled\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[31], line 23\u001b[0m, in \u001b[0;36mTabularDataset.__init__\u001b[1;34m(self, df_x, df_y, mean, std, normalise)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m# Normalize the data if needed\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalise:\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd)\n",
            "Cell \u001b[1;32mIn[31], line 58\u001b[0m, in \u001b[0;36mTabularDataset.normalize_data\u001b[1;34m(self, data, mean, std)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_data\u001b[39m(\u001b[39mself\u001b[39m, data, mean, std):\n\u001b[0;32m     47\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m    Normalize the data using mean and standard deviation values.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m    - normalized_data (np.array): Normalized data.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     normalized_data \u001b[39m=\u001b[39m (data \u001b[39m-\u001b[39;49m mean) \u001b[39m/\u001b[39m std\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m normalized_data\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:2016\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   2013\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array_ufunc__\u001b[39m(\n\u001b[0;32m   2014\u001b[0m     \u001b[39mself\u001b[39m, ufunc: np\u001b[39m.\u001b[39mufunc, method: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39minputs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[0;32m   2015\u001b[0m ):\n\u001b[1;32m-> 2016\u001b[0m     \u001b[39mreturn\u001b[39;00m arraylike\u001b[39m.\u001b[39;49marray_ufunc(\u001b[39mself\u001b[39;49m, ufunc, method, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arraylike.py:273\u001b[0m, in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m kwargs \u001b[39m=\u001b[39m _standardize_out_kwarg(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    272\u001b[0m \u001b[39m# for binary ops, use our custom dunder methods\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m result \u001b[39m=\u001b[39m maybe_dispatch_ufunc_to_dunder_op(\u001b[39mself\u001b[39;49m, ufunc, method, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    274\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m    275\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\ops_dispatch.pyx:113\u001b[0m, in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arraylike.py:198\u001b[0m, in \u001b[0;36mOpsMixin.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__rsub__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__rsub__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, roperator\u001b[39m.\u001b[39;49mrsub)\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:6108\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[0;32m   6107\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[1;32m-> 6108\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:1350\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   1348\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[1;32m-> 1350\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_result(result, name\u001b[39m=\u001b[39;49mres_name)\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:3101\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[1;34m(self, result, name)\u001b[0m\n\u001b[0;32m   3098\u001b[0m \u001b[39m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[0;32m   3099\u001b[0m \u001b[39m#  JSONArray tests\u001b[39;00m\n\u001b[0;32m   3100\u001b[0m dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(result, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 3101\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(result, index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   3102\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[0;32m   3104\u001b[0m \u001b[39m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[0;32m   3105\u001b[0m \u001b[39m#  would set it back to self.name\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:500\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    498\u001b[0m     index \u001b[39m=\u001b[39m default_index(\u001b[39mlen\u001b[39m(data))\n\u001b[0;32m    499\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n\u001b[1;32m--> 500\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(data, index)\n\u001b[0;32m    502\u001b[0m \u001b[39m# create/copy the manager\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
            "File \u001b[1;32mc:\\Users\\Paul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Length of values (61648) does not match length of index (14)"
          ]
        }
      ],
      "source": [
        "# TODO : define new datasets with mean, std and normalise=True\n",
        "# be careful with the labels, they should start from 0!\n",
        "\n",
        "# Calculate mean and standard deviation for the train set\n",
        "\n",
        "train_y = train_y.astype(float).astype(int)\n",
        "train_mean = train_X.mean()\n",
        "train_std = train_X.std()\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "\n",
        "# Create new datasets with mean, std, and normalization\n",
        "train_dataset = TabularDataset(train_X, train_y, mean=train_mean, std=train_std, normalise=True)\n",
        "test_dataset = TabularDataset(test_X, test_y, mean=train_mean, std=train_std, normalise=True)\n",
        "\n",
        "# Create the data loaders with the specified batch size and shuffled\n",
        "batch_size = 256\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "N28MlXQ7ON1j",
      "metadata": {
        "id": "N28MlXQ7ON1j"
      },
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NT-EtgZKOLb0",
      "metadata": {
        "id": "NT-EtgZKOLb0"
      },
      "outputs": [],
      "source": [
        "class LR(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The logistic regression model inherits from torch.nn.Module \n",
        "    which is the base class for all neural network modules.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        \"\"\" Initializes internal Module state. \"\"\"\n",
        "        super(LR, self).__init__()\n",
        "        # TODO define linear layer for the model\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Defines the computation performed at every call. \"\"\"\n",
        "        # What are the dimensions of your input layer?\n",
        "        x = x.to(torch.float32)\n",
        "        # TODO run the data through the layer\n",
        "        \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eWDd_hYGOZSj",
      "metadata": {
        "id": "eWDd_hYGOZSj"
      },
      "outputs": [],
      "source": [
        "## TODO define model, loss and optimisers\n",
        "## don't forget to move everything for the correct devices\n",
        "## \n",
        "lr=0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6EFwKn-iOgNv",
      "metadata": {
        "id": "6EFwKn-iOgNv"
      },
      "outputs": [],
      "source": [
        "## TODO train the network\n",
        "num_epochs = 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H-IJWOsATYul",
      "metadata": {
        "id": "H-IJWOsATYul"
      },
      "outputs": [],
      "source": [
        "## todo - plot losses and accuracies\n",
        "plot('Epoch vs. Loss', 'Loss', train_losses_lr, val_losses_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HjAaYdd8TZed",
      "metadata": {
        "id": "HjAaYdd8TZed"
      },
      "outputs": [],
      "source": [
        "plot('Epoch vs. Accuracy', 'Accuracy', train_accs_lr, val_accs_lr)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cb1bca9a",
      "metadata": {
        "id": "cb1bca9a"
      },
      "source": [
        "\n",
        "## Create a simple MLP\n",
        "\n",
        "As the default tree has 3 layers, let's make a MLP with 3 linear layers and ReLU.\n",
        "Please notice that making convolutions on tabular data does not make much sense even though it is technically possible.   \n",
        "\n",
        "**TODO :** Explain why making convolutions on tabular data does not make much sense. Why do we use an MLP, not a CNN from the previous homework?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eecbb52",
      "metadata": {
        "id": "4eecbb52"
      },
      "outputs": [],
      "source": [
        "class TabularNetwork(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        \"\"\" Initializes internal Module state. \"\"\"\n",
        "        super(TabularNetwork, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            # TODO : define 3 linear layer with sizes \n",
        "            # input_dim -> input_dim // 2 -> output_dim\n",
        "            # using ReLU as nonlinearity\n",
        "            \n",
        "        )\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Defines the computation performed at every call. \"\"\"\n",
        "        # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5OGid8SpMvZz",
      "metadata": {
        "id": "5OGid8SpMvZz"
      },
      "outputs": [],
      "source": [
        "## TODO : define model, optimiser, cross entropy loss,\n",
        "## put model to the device, and train mode\n",
        "## you can optionally apply regularisation between 0.0005 and 0.005 \n",
        "lr=0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z-WNxtczM5Iv",
      "metadata": {
        "id": "Z-WNxtczM5Iv"
      },
      "outputs": [],
      "source": [
        "## TODO : Train model\n",
        "num_epochs = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I_xVns4qM5eO",
      "metadata": {
        "id": "I_xVns4qM5eO"
      },
      "outputs": [],
      "source": [
        "# TODO plot losses\n",
        "plot('Epoch vs. Loss', 'Loss', train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JRAEaYnYUpd_",
      "metadata": {
        "id": "JRAEaYnYUpd_"
      },
      "outputs": [],
      "source": [
        "# TODO plot accuracies\n",
        "plot('Epoch vs. Accuracy', 'Accuracy', train_accs, val_accs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "J8HbVqiUznBu",
      "metadata": {
        "id": "J8HbVqiUznBu"
      },
      "source": [
        "**TODO:** Did your network perform better or worse than the GradientBoostingClassifier on this dataset? Why? \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cc0f5f87",
      "metadata": {
        "id": "cc0f5f87"
      },
      "source": [
        "## Bonus tasks (optional)\n",
        "* Try to use SGD instead of Adam as optimiser. What do you notice?\n",
        "Here are different opinions on this topic:\n",
        "  * https://codeahoy.com/questions/ds-interview/33/#:~:text=Adam%20tends%20to%20converge%20faster,converges%20to%20more%20optimal%20solutions.\n",
        "  * https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/ \n",
        "  * https://datascience.stackexchange.com/questions/30344/why-not-always-use-the-adam-optimization-technique\n",
        "\n",
        "* Try to make your MLP twice deeper. What do you notice? Why?\n",
        "\n",
        "## Advanced topic to read about:\n",
        "**Tools which may be helpful for data exploration:**\n",
        "* df.describe() - returns some basic statistics for your dataset - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
        "* ydata-profiling (previous pandas-profiling) - generates interactive data exploration report: basic statistics, nans, correlations between different features - https://github.com/ydataai/ydata-profiling\n",
        "\n",
        "**Tree libraries**\n",
        "* XGBoost - XGBoost stands for â€œExtreme Gradient Boostingâ€, where the term â€œGradient Boostingâ€ originates from the paper Greedy Function Approximation: A Gradient Boosting Machine, by Friedman. https://xgboost.readthedocs.io/en/stable/tutorials/model.html\n",
        "* LightGBM - industrial library for XGBoost from Miscrosoft. LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient. https://lightgbm.readthedocs.io/en/v3.3.2/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fc6bdb0a",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
